# LLM Planning Output Mapped to Robot Controllers

The mapping of LLM planning output to robot controllers represents the critical bridge between high-level cognitive planning and low-level robot execution. This process transforms abstract plans generated by large language models into specific control commands that drive robot actuators, sensors, and other hardware components. The mapping process must preserve the intent and structure of the high-level plan while ensuring compatibility with the robot's control architecture and safety constraints.

## Understanding the Mapping Process

### Abstract to Concrete Transformation

The mapping process involves transforming abstract planning elements into concrete control commands:

```
LLM Plan: "Navigate to kitchen, grasp glass, fill with water"
    ↓
Task Decomposition: [Navigation] → [Manipulation] → [Filling]
    ↓
Action Primitives: [GoToPose] → [GraspObject] → [ControlValve]
    ↓
Controller Commands: [NavigationController] → [ManipulationController] → [ValveController]
    ↓
Hardware Execution: [Wheels/Motors] → [Gripper/Actuators] → [Water Valve]
```

### Mapping Architecture

The mapping system typically consists of several layers:

#### Planning Interface Layer
- **Plan Parser**: Interprets the LLM-generated plan structure
- **Action Classifier**: Categorizes actions into robot capability types
- **Parameter Extractor**: Extracts specific parameters from the plan
- **Constraint Validator**: Validates plan feasibility against robot constraints

#### Control Mapping Layer
- **Action-to-Controller Mapper**: Maps high-level actions to specific controllers
- **Parameter Converter**: Transforms abstract parameters to controller-specific values
- **Sequence Coordinator**: Orchestrates the execution sequence
- **Safety Validator**: Ensures all commands pass safety checks

#### Execution Interface Layer
- **Controller Interface**: Communicates with individual robot controllers
- **Feedback Integrator**: Collects and processes feedback from controllers
- **Execution Monitor**: Tracks plan execution progress
- **Recovery Handler**: Manages execution failures and recovery

## Controller Types and Mapping Strategies

### Navigation Controllers

#### Differential Drive Controllers
For wheeled robots with differential drive systems:

```cpp
// LLM Plan: "Move forward 2 meters"
struct NavigationPlan {
    std::string action = "navigate";
    double distance = 2.0;
    double angle = 0.0;
    std::string frame = "base_link";
};

// Mapping to controller
void mapToDifferentialDrive(const NavigationPlan& plan) {
    geometry_msgs::msg::Twist cmd_vel;

    // Convert distance to velocity commands
    cmd_vel.linear.x = calculateLinearVelocity(plan.distance);
    cmd_vel.angular.z = calculateAngularVelocity(plan.angle);

    // Publish to differential drive controller
    velocity_publisher_->publish(cmd_vel);
}
```

#### Holonomic Controllers
For robots with omnidirectional movement capabilities:

```cpp
// LLM Plan: "Move to position [3.5, 2.1]"
struct PoseGoal {
    double x, y, theta;
    std::string frame = "map";
};

// Mapping to navigation controller
void mapToHolonomic(const PoseGoal& goal) {
    auto nav_goal = nav2_msgs::action::NavigateToPose::Goal();
    nav_goal.pose.header.frame_id = goal.frame;
    nav_goal.pose.pose.position.x = goal.x;
    nav_goal.pose.pose.position.y = goal.y;
    nav_goal.pose.pose.orientation = tf2::toMsg(tf2::Quaternion(0, 0, goal.theta));

    // Send to navigation action server
    auto future = nav_client_->async_send_goal(nav_goal);
}
```

### Manipulation Controllers

#### Joint Space Controllers
For precise joint-level control:

```cpp
// LLM Plan: "Open gripper to 5cm width"
struct GraspPlan {
    std::string action = "grasp";
    double gripper_width = 0.05;  // 5cm
    double grasp_force = 10.0;    // Newtons
};

// Mapping to joint controller
void mapToJointController(const GraspPlan& plan) {
    control_msgs::msg::JointTrajectoryGoal joint_goal;

    // Configure gripper joints
    joint_goal.trajectory.joint_names = {"left_gripper_joint", "right_gripper_joint"};

    trajectory_msgs::msg::JointTrajectoryPoint point;
    point.positions = {plan.gripper_width/2.0, plan.gripper_width/2.0};  // Symmetric gripper
    point.velocities = {0.1, 0.1};
    point.effort = {plan.grasp_force, plan.grasp_force};

    joint_goal.trajectory.points.push_back(point);

    // Send to joint trajectory controller
    joint_client_->send_goal(joint_goal);
}
```

#### Cartesian Controllers
For end-effector position and orientation control:

```cpp
// LLM Plan: "Move arm to grasp object at [1.2, 0.8, 0.9]"
struct CartesianPlan {
    double x, y, z;
    double roll, pitch, yaw;
    std::string frame = "base_link";
};

// Mapping to Cartesian controller
void mapToCartesianController(const CartesianPlan& plan) {
    geometry_msgs::msg::PoseStamped target_pose;
    target_pose.header.frame_id = plan.frame;
    target_pose.pose.position.x = plan.x;
    target_pose.pose.position.y = plan.y;
    target_pose.pose.position.z = plan.z;

    // Convert Euler angles to quaternion
    tf2::Quaternion quat;
    quat.setRPY(plan.roll, plan.pitch, plan.yaw);
    target_pose.pose.orientation = tf2::toMsg(quat);

    // Send to Cartesian controller
    cartesian_client_->send_goal(target_pose);
}
```

### Perception Controllers

#### Camera Controllers
For controlling perception systems:

```cpp
// LLM Plan: "Look for glass in front of robot"
struct PerceptionPlan {
    std::string target_object = "glass";
    std::string sensor_type = "camera";
    double horizontal_fov = 60.0;  // degrees
    double vertical_fov = 45.0;    // degrees
};

// Mapping to camera controller
void mapToCameraController(const PerceptionPlan& plan) {
    sensor_msgs::msg::CameraInfo camera_info;
    camera_info.header.frame_id = "camera_link";
    camera_info.height = 480;
    camera_info.width = 640;
    camera_info.distortion_model = "plumb_bob";

    // Configure camera parameters based on plan
    camera_info.d = {0.0, 0.0, 0.0, 0.0, 0.0};  // distortion coefficients
    camera_info.k = {320, 0.0, 320, 0.0, 320, 240, 0.0, 0.0, 1.0};  // intrinsic matrix

    // Publish camera configuration
    camera_config_publisher_->publish(camera_info);

    // Trigger object detection
    vision_msgs::srv::DetectObjects::Request::SharedPtr request;
    request->roi.min_x = 0;
    request->roi.min_y = 0;
    request->roi.max_x = 640;
    request->roi.max_y = 480;
    request->object_classes = {plan.target_object};

    detection_client_->async_send_request(request);
}
```

## Mapping Validation and Safety

### Pre-Mapping Validation

Before mapping LLM plans to controllers, validation ensures safety and feasibility:

```cpp
class PlanValidator {
public:
    bool validatePlan(const LLMPlan& plan, const RobotModel& model) {
        for (const auto& action : plan.actions) {
            if (!validateAction(action, model)) {
                return false;
            }
        }
        return true;
    }

private:
    bool validateAction(const PlanAction& action, const RobotModel& model) {
        switch (action.type) {
            case ActionType::NAVIGATION:
                return validateNavigationAction(action, model);
            case ActionType::MANIPULATION:
                return validateManipulationAction(action, model);
            case ActionType::PERCEPTION:
                return validatePerceptionAction(action, model);
            default:
                return false;
        }
    }

    bool validateNavigationAction(const PlanAction& action, const RobotModel& model) {
        // Check if target pose is in navigable space
        auto pose = action.parameters.get<geometry_msgs::msg::Pose>("target_pose");
        if (!model.isNavigable(pose)) {
            return false;
        }

        // Check if path is collision-free
        auto path = model.planPath(model.getCurrentPose(), pose);
        return model.isPathCollisionFree(path);
    }

    bool validateManipulationAction(const PlanAction& action, const RobotModel& model) {
        // Check if target pose is in manipulator workspace
        auto pose = action.parameters.get<geometry_msgs::msg::Pose>("target_pose");
        if (!model.isInWorkspace(pose)) {
            return false;
        }

        // Check if grasp is feasible
        auto grasp_type = action.parameters.get<std::string>("grasp_type");
        return model.isGraspFeasible(pose, grasp_type);
    }
};
```

### Real-Time Safety Monitoring

During execution, continuous monitoring ensures safety:

```cpp
class SafetyMonitor {
public:
    SafetyStatus checkSafety(const ControllerCommand& cmd, const SensorFeedback& feedback) {
        SafetyStatus status;

        // Check joint limits
        status.joint_limits_ok = checkJointLimits(cmd);

        // Check velocity limits
        status.velocity_ok = checkVelocityLimits(cmd);

        // Check collision avoidance
        status.collision_free = checkCollisionAvoidance(cmd, feedback);

        // Check force limits
        status.force_ok = checkForceLimits(cmd, feedback);

        return status;
    }

private:
    bool checkJointLimits(const ControllerCommand& cmd) {
        for (size_t i = 0; i < cmd.joint_positions.size(); ++i) {
            if (cmd.joint_positions[i] < joint_limits_[i].min ||
                cmd.joint_positions[i] > joint_limits_[i].max) {
                return false;
            }
        }
        return true;
    }

    bool checkCollisionAvoidance(const ControllerCommand& cmd, const SensorFeedback& feedback) {
        // Check planned trajectory against current obstacle map
        auto trajectory = generateTrajectory(cmd);
        return !hasCollision(trajectory, feedback.obstacle_map);
    }
};
```

## Feedback Integration and Plan Adaptation

### Closed-Loop Control

The mapping system integrates feedback to adapt plans during execution:

```cpp
class AdaptivePlanner {
public:
    void executeWithFeedback(const LLMPlan& initial_plan) {
        LLMPlan current_plan = initial_plan;

        for (size_t step = 0; step < current_plan.actions.size(); ++step) {
            const auto& action = current_plan.actions[step];

            // Execute action
            auto result = executeAction(action);

            // Integrate feedback
            auto feedback = sensor_feedback_handler_.getFeedback();
            auto updated_plan = adaptPlan(current_plan, step, feedback);

            if (result.success) {
                current_plan = updated_plan;
                continue;
            } else {
                // Handle failure
                auto recovery_plan = generateRecoveryPlan(current_plan, step, feedback);
                executeRecoveryPlan(recovery_plan);

                // Resume original plan or modify as needed
                current_plan = updatePlanAfterRecovery(current_plan, step, recovery_plan);
            }
        }
    }

private:
    PlanResult executeAction(const PlanAction& action) {
        // Map action to controller commands
        auto controller_cmd = mapToController(action);

        // Execute and monitor
        auto result = controller_interface_.executeCommand(controller_cmd);

        return result;
    }

    LLMPlan adaptPlan(const LLMPlan& original_plan, size_t current_step,
                     const SensorFeedback& feedback) {
        LLMPlan adapted_plan = original_plan;

        // Check if current environment differs from plan assumptions
        if (environmentChanged(feedback)) {
            // Re-plan remaining steps based on new information
            auto replan_request = generateReplanRequest(original_plan, current_step, feedback);
            auto new_subplan = llm_replanner_.replan(replan_request);

            // Integrate new subplan
            adapted_plan.actions.erase(adapted_plan.actions.begin() + current_step + 1,
                                     adapted_plan.actions.end());
            adapted_plan.actions.insert(adapted_plan.actions.end(),
                                       new_subplan.actions.begin(),
                                       new_subplan.actions.end());
        }

        return adapted_plan;
    }
};
```

### Dynamic Parameter Adjustment

Controllers may need dynamic parameter adjustment based on feedback:

```cpp
class ParameterAdapter {
public:
    ControllerParameters adaptParameters(const PlanAction& action,
                                      const SensorFeedback& feedback) {
        ControllerParameters params = getBaseParameters(action);

        // Adjust based on environmental conditions
        if (feedback.surface_friction < 0.3) {
            params.velocity_scale *= 0.7;  // Slow down on slippery surfaces
            params.acceleration_limit *= 0.5;
        }

        // Adjust based on object properties
        if (action.type == ActionType::MANIPULATION) {
            auto object_weight = estimateObjectWeight(feedback);
            params.force_limit = calculateSafeForceLimit(object_weight);
        }

        // Adjust based on precision requirements
        if (action.requires_high_precision) {
            params.velocity_scale *= 0.3;  // Slow down for precision tasks
            params.pid_gains = high_precision_gains_;
        }

        return params;
    }

private:
    ControllerParameters getBaseParameters(const PlanAction& action) {
        ControllerParameters params;

        switch (action.type) {
            case ActionType::NAVIGATION:
                params.velocity_scale = 0.5;
                params.acceleration_limit = 0.5;
                params.force_limit = 0.0;  // No force limit for navigation
                break;
            case ActionType::MANIPULATION:
                params.velocity_scale = 0.3;
                params.acceleration_limit = 0.3;
                params.force_limit = 20.0;  // 20N force limit
                break;
            default:
                params.velocity_scale = 0.5;
                params.acceleration_limit = 0.5;
                params.force_limit = 0.0;
        }

        return params;
    }
};
```

## Implementation Patterns

### Factory Pattern for Controller Mapping

Using a factory pattern to handle different robot configurations:

```cpp
class ControllerMapperFactory {
public:
    static std::unique_ptr<ControllerMapper> createMapper(const RobotDescription& robot_desc) {
        if (robot_desc.type == "differential_drive") {
            return std::make_unique<DifferentialDriveMapper>(robot_desc);
        } else if (robot_desc.type == "omnidirectional") {
            return std::make_unique<OmnidirectionalMapper>(robot_desc);
        } else if (robot_desc.type == "manipulator") {
            return std::make_unique<ManipulatorMapper>(robot_desc);
        } else if (robot_desc.type == "humanoid") {
            return std::make_unique<HumanoidMapper>(robot_desc);
        }

        throw std::runtime_error("Unsupported robot type: " + robot_desc.type);
    }
};

class ControllerMapper {
public:
    virtual ControllerCommand mapAction(const PlanAction& action) = 0;
    virtual bool validateAction(const PlanAction& action) = 0;
    virtual std::vector<std::string> getSupportedActions() = 0;
};

class DifferentialDriveMapper : public ControllerMapper {
public:
    ControllerCommand mapAction(const PlanAction& action) override {
        if (action.type == ActionType::NAVIGATION) {
            return mapNavigationToVelocity(action);
        }
        throw std::runtime_error("Unsupported action type for differential drive");
    }

private:
    ControllerCommand mapNavigationToVelocity(const PlanAction& action) {
        ControllerCommand cmd;
        cmd.type = ControllerCommand::TYPE_VELOCITY;

        auto target_pose = action.parameters.get<geometry_msgs::msg::Pose>("target_pose");
        auto current_pose = getCurrentPose();

        // Calculate required linear and angular velocities
        auto [linear_vel, angular_vel] = calculateVelocities(current_pose, target_pose);

        cmd.velocity.linear.x = linear_vel;
        cmd.velocity.angular.z = angular_vel;

        return cmd;
    }
};
```

### Strategy Pattern for Different Mapping Approaches

Different mapping strategies for various scenarios:

```cpp
class MappingStrategy {
public:
    virtual ControllerCommand map(const PlanAction& action,
                                const RobotState& state) = 0;
    virtual std::string getName() const = 0;
};

class ConservativeMappingStrategy : public MappingStrategy {
public:
    ControllerCommand map(const PlanAction& action, const RobotState& state) override {
        ControllerCommand cmd = base_map(action, state);

        // Apply conservative safety margins
        cmd.velocity *= 0.7;  // Reduce speed by 30%
        cmd.acceleration *= 0.5;  // Reduce acceleration by 50%
        cmd.force_limit *= 0.8;   // Reduce force limit by 20%

        return cmd;
    }

    std::string getName() const override { return "conservative"; }
};

class AggressiveMappingStrategy : public MappingStrategy {
public:
    ControllerCommand map(const PlanAction& action, const RobotState& state) override {
        ControllerCommand cmd = base_map(action, state);

        // Optimize for efficiency while maintaining safety
        cmd.velocity *= 1.2;  // Increase speed by 20% (within limits)
        cmd.acceleration *= 1.1;  // Increase acceleration by 10%

        return cmd;
    }

    std::string getName() const override { return "aggressive"; }
};

class AdaptiveMappingStrategy : public MappingStrategy {
public:
    ControllerCommand map(const PlanAction& action, const RobotState& state) override {
        // Choose strategy based on current context
        auto strategy = selectStrategy(action, state);
        return strategy->map(action, state);
    }

    std::string getName() const override { return "adaptive"; }

private:
    std::unique_ptr<MappingStrategy> selectStrategy(const PlanAction& action,
                                                  const RobotState& state) {
        if (state.environment_hazard_level > 0.7) {
            return std::make_unique<ConservativeMappingStrategy>();
        } else if (action.requires_high_precision) {
            return std::make_unique<ConservativeMappingStrategy>();
        } else if (state.battery_level < 0.2) {
            return std::make_unique<ConservativeMappingStrategy>();
        } else {
            return std::make_unique<AggressiveMappingStrategy>();
        }
    }
};
```

## Performance Considerations

### Real-Time Requirements

Mapping systems must meet real-time constraints:

```cpp
class RealTimeMapper {
public:
    ControllerCommand mapAction(const PlanAction& action) {
        auto start_time = std::chrono::high_resolution_clock::now();

        // Perform mapping
        auto cmd = performMapping(action);

        auto end_time = std::chrono::high_resolution_clock::now();
        auto duration = std::chrono::duration_cast<std::chrono::microseconds>(
            end_time - start_time).count();

        // Log performance metrics
        if (duration > MAX_MAPPING_TIME_US) {
            RCLCPP_WARN(node_->get_logger(),
                       "Mapping took %ld microseconds, exceeding limit of %d",
                       duration, MAX_MAPPING_TIME_US);
        }

        return cmd;
    }

private:
    static constexpr int MAX_MAPPING_TIME_US = 1000;  // 1ms limit
    rclcpp::Node* node_;
};
```

### Caching and Optimization

Caching frequently used mappings for performance:

```cpp
class CachedMapper {
public:
    ControllerCommand mapAction(const PlanAction& action) {
        // Create cache key from action parameters
        auto cache_key = generateCacheKey(action);

        // Check cache first
        if (cache_.contains(cache_key)) {
            return cache_[cache_key];
        }

        // Perform mapping if not in cache
        auto cmd = performMapping(action);

        // Store in cache
        cache_[cache_key] = cmd;

        return cmd;
    }

private:
    std::string generateCacheKey(const PlanAction& action) {
        // Generate key based on action type and parameters
        std::stringstream key_stream;
        key_stream << action.type << "_" << action.target_pose.position.x
                   << "_" << action.target_pose.position.y;
        return key_stream.str();
    }

    std::unordered_map<std::string, ControllerCommand> cache_;
    static constexpr size_t MAX_CACHE_SIZE = 1000;
};
```

## Learning Outcomes

After studying this section, you should be able to:
- Understand the process of mapping LLM planning output to robot controllers
- Identify different controller types and their mapping strategies
- Implement validation and safety mechanisms for plan execution
- Design feedback integration systems for adaptive planning
- Apply design patterns for flexible and maintainable mapping systems
- Consider performance requirements for real-time mapping

## Key Insights

### Critical Translation Layer
The mapping layer is critical for translating abstract plans into executable robot actions while maintaining safety and feasibility.

### Multi-Controller Coordination
Complex tasks require coordination between multiple controllers, each specialized for different aspects of robot behavior.

### Safety-First Approach
All mapping operations must prioritize safety, with validation at every step of the process.

### Adaptive Capabilities
Robust systems must adapt to changing conditions and incorporate feedback during execution.

## Summary

The mapping of LLM planning output to robot controllers is a critical component of cognitive robotic systems, bridging the gap between high-level reasoning and low-level execution. This process requires careful consideration of safety, feasibility, and real-time constraints while maintaining the intent and structure of the original plan. Success depends on proper validation, feedback integration, and adaptive capabilities that allow the system to respond to changing conditions during execution. The mapping system must be designed with appropriate architectural patterns to handle different robot configurations and operational scenarios while ensuring safe and reliable robot behavior.